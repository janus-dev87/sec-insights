previewsEnabled: true
databases:
  - name: llama-app-db
    databaseName: llama_app_db
    plan: pro
    previewPlan: starter

services:
  # A Docker web service
  # Docs for Render blueprints:
  # https://render.com/docs/blueprint-spec
  - type: web
    name: llama-app-backend
    runtime: docker
    repo: https://github.com/run-llama/sec-insights.git
    region: oregon
    plan: standard
    rootDir: ./backend
    # https://render.com/docs/blueprint-spec#scaling
    scaling:
      minInstances: 2
      maxInstances: 10
      targetMemoryPercent: 75 # optional if targetCPUPercent is set (valid: 1-90)
      targetCPUPercent: 75 # optional if targetMemory is set (valid: 1-90)
    healthCheckPath: /api/health/
    initialDeployHook: make seed_db_based_on_env
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: llama-app-db
          property: connectionString
      - fromGroup: general-settings
      - fromGroup: prod-web-secrets
      - fromGroup: preview-web-secrets
  # A Docker cron service
  # Runs the seed_db job which should only be upserts and otherwise idempotent
  - type: cron
    name: llama-app-cron
    runtime: docker
    repo: https://github.com/run-llama/sec-insights.git
    region: oregon
    plan: standard
    rootDir: ./backend
    # set to the fake date of Feb 31st so it never runs. Meant to be manually triggered.
    schedule: "0 5 31 2 ?"
    dockerCommand: make seed_db_based_on_env
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: llama-app-db
          property: connectionString
      - fromGroup: general-settings
      - fromGroup: prod-web-secrets
      - fromGroup: preview-web-secrets
envVarGroups:
- name: general-settings
  envVars:
    - key: IS_PREVIEW_ENV
      value: false
      previewValue: true
    - key: LOG_LEVEL
      value: INFO
      previewValue: DEBUG
    - key: BACKEND_CORS_ORIGINS
      value: '["http://localhost", "http://localhost:8000", "http://localhost:3000", "http://127.0.0.1:3000", "https://llama-app-backend.onrender.com", "https://llama-app-frontend.vercel.app", "http://secinsights.ai", "http://www.secinsights.ai", "https://secinsights.ai", "https://www.secinsights.ai"]'
    # S3_BUCKET_NAME is the bucket used for the StorageContext of the backend's LlamaIndex chat engine
    - key: S3_BUCKET_NAME
      value: llama-app-backend-prod
      previewValue: llama-app-backend-preview
    # S3_ASSET_BUCKET_NAME is the bucket used for app assets (e.g. document PDFs)
    - key: S3_ASSET_BUCKET_NAME
      value: llama-app-web-assets-prod
      previewValue: llama-app-web-assets-preview
    - key: CDN_BASE_URL
      value: https://d687lz8k56fia.cloudfront.net
      previewValue: https://dl94gqvzlh4k8.cloudfront.net
    - key: SENTRY_DSN
      sync: false
- name: prod-web-secrets
  envVars:
    # Manually add a prod value for OPENAI_API_KEY in Render dashboard
    - key: OPENAI_API_KEY
      sync: false
    - key: AWS_KEY
      sync: false
    - key: AWS_SECRET
      sync: false
    - key: POLYGON_IO_API_KEY
      sync: false
- name: preview-web-secrets
  envVars:
    # All env vars in this group should be prefixed with "PREVIEW_"
    # Manually add a preview value for PREVIEW_OPENAI_API_KEY in Render dashboard
    - key: PREVIEW_OPENAI_API_KEY
      sync: false
    - key: PREVIEW_AWS_KEY
      sync: false
    - key: PREVIEW_AWS_SECRET
      sync: false
    - key: PREVIEW_POLYGON_IO_API_KEY
      sync: false
